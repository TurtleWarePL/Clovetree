\part{Internals}

\chapter{Implementation of the user model}

The implementation of the user model pretty much reflects the model
itself, except that the implementation of the \emph{slice} is not a
simple sequence of elements.

Instead, a \emph{slice} is a sequence of a user-invisible type called
a \emph{bar}.  We introduced this additional type to simplify the
layout algorithm.  A bar contains all the non-barline elements
between two barlines.  The layout algorithm therefore does not
have to start by finding the barlines in the sequence, but can
directly line up the material between barlines.

The implementation of the model is actually spread out in three
different files:

\begin{itemize} 
\item \texttt{buffer.lisp}: This file is the one that most immediately
  corresponds to the user model.  Generic functions allow insertion
  and deletion of the different types used to implement the model.
  Currently, the implementation of various sequences is in the form of
  simple Lisp lists.  We might change that one day for performance
  reasons, but then again, it may not be necessary. 
\item \texttt{numbering.lisp}: This file observes the action (through
  :before, :after, and :around methods) of the basic operations in
  order to number different instances of the basic types.  This allows
  us to know at any point in time whether an instance precedes another
  in a sequence.  The implementation of the numbering scheme is not
  very efficient at the moment, but it might not matter since
  sequences are fairly short in general.
\item \texttt{cursor.lisp}: This file implements cursor operations.
  It observes operations in the preceding two files in order to move
  around cursors.  
\end{itemize}

A cursor has two slots, a bar in which it is located, and the position
within the bar.  Cursors are inserted on most of the model types (bar,
slice, segment, buffer) so that when one of those elements is deleted,
the cursor can be moved accordingly.  Things get complicated because
we want to allow for an arbitrary number of cursors, each attached to
a different window, though we do not currently take advantage of that
possibility.

%======================================================
\inputtex{buffer.tex}
%======================================================
\chapter{The Layout algorithm}

\section{Purpose}

The purpose of the layout algorithm is to divide the entire score into
displayed units.  Currently, these units are \emph{lines}, where a
line is the part of system displayed in sequence from left to right.
In the future, it will be possible to use \emph{pages} as units which
will make things a bit more realistic.  Since we currently do not have
pages, our display is mostly in the form of a ``roll of paper''.

\section{What it needs to recompute}

The layout algorithm is invoked after each keystroke.  But in order to
do its work correctly, it has to know what has been damaged between
two invocations.  The user can have executed some arbitrary code
between two such invocations, and in order not to have to recompute
the entire score each time, it preserves the result of its calculation
between invocations and only recompute what is necessary. 

To know what has been damaged, the layout algorithm (in the file
\texttt{measure.lisp}) installs a different set of \texttt{:before},
\texttt{:after}, and \texttt{:around} methods to observe the
operations on the fundamental implementation of the user model.
Currently, it does its work in a very crude way.  Whenever the
structure has been modified in any way, the entire segment is marked
as modified and will be totally recomputed at the next invocation. 

Recomputing the layout involves computing, for each segment, a
sequence of \emph{measures}\index{measure}.  This is a user-invisible
type that corresponds to the superimposition of simultaneous bars in
overlapping layers.  We could be more careful about marking things as
damaged, and preserve measures that contain bars that have not been
modified.  We might do that if performance requires it.  At the
moment, we have no reason to believe that it will be necessary.  

\section{The importance of segments}

The importance of the concept of a segment should now be clear.
If the user deletes a barline, all measures to the right of the
point of deletion \emph{within the same segment} must be recomputed,
since the musical material will no longer line up the same way.  Had
the score been a single segment, we would have had to potentially
recompute the entire score in such situations.  In addition, it would
be pretty annoying to the user not to be able to count on finished
material far from the cursor to remain intact.  Thus, the concept of a
segment both helps the user organize his material and helps the
implementor limit the damage that needs to be repaired by the layout
algorithm. 

\section{Head and tail slices}

There is a slight problem with \emph{head slices} and \emph{tail
slices} which is why they are not implemented yet.  While
conceptually these slices belong to the segment of their
corresponding layer, the layout algorithm must align them with the
last measure of the previous segment and the first measure of the
next segment.  To make it impossible for those slices to stick out
arbitrarily far, we do not allow for head and tail slices to contain
barlines.  This limits the stick-out to the previous and the
next segments.  We have not yet decided how to manage these slices.
Probably, a modification would have to mark the previous or the next
segment as damaged, or at least the last measure or the first measure
in these segments.  

\section{The concept of a measure}

A measure, as far as the layout algorithm is concerned, only contains
some very limited amount of information about its bars so that it will
know how much room the measure will take up on a given line of musical
material. 

The main problem we need to address is the fact that a measure takes
up a different amount of space according to the contents of the other
measures of the same line.  The remainder of this section will discuss
how we solve that problem.

First, let us introduce the concept of a \emph{time line}\index{time
line}. A time line represents a moment in time in a given measure such
that the measure has some event (like notes) that start at that moment
in time.  The \emph{duration}\index{duration!of a time line|)} of the
time line is the temporal distance between it and the following one in
the measure, or, if it is the last one, the duration of the longest
lasting event that starts at the moment in time. 

From the art of music engraving, we know that a longer temporal
distance requires a longer geographic distance on the score as well,
but that is not all there is to it.  In fact, we also know that
\emph{on a given line}, the smallest geographic distance possible (a
global parameter of the score that determines denseness and that we
will call $w_{min}$) is assigned to the shortest temporal distance on
that line, \emph{independently of the absolute value of that temporal
distance}. The other geographic distances are adjusted accordingly.
Thus, a measure can take up a lot more space on a line if other
measures on the same line have shorter minimal temporal distances
between time lines than itself.

From the articles published about the Lime score editor, we use the
following formula relating the ratio between the geographic distance
of two time lines to the ratio of their durations:

$w_2 / w_1 = {(d_2 / d_1)}^k$

where $w_1$ and $w_2$ are the ``widths'', i.e. geographic distances of
the two time lines, and $d_1$ and $d_2$ are their durations. The
parameter $k$ takes on values between $0$ and $1$, where $0$ gives
constant spacing (space is independent of duration) and $1$ gives
proportional spacing.  A good value for $k$ seems to be around $0.6$. 

On a given line, with a smallest temporal distance $d_{min}$ between
any adjacent time lines, we can express the geographic distance
$w$ following any time line with duration $d$ as:

$w = w_{min} {(d / d_{min})}^k$

Let us now define the \emph{natural width} of a measure as:

$W_{nm} = \sum_i w_{min} {(d_i / d_{min})}^k$

where $d_i$ is the duration of the $i$th time line of the measure, and
the \emph{natural width} of a line $W_{nl}$ as the sum of the natural
widths of the measures of the line.  

We can rewrite the formula above as:

$W_{nm} = {(1 / d_{min})}^k w_{min}  \sum_i {d_i}^k$

Where $w_{min}  \sum_i {d_i}^k$ is a property of a measure that
remains constant as long as the two global parameters $w_{min}$ and
$k$ do not change.  We shall call this property the \emph{measure
coefficient}.  To get the natural width of the measure, it suffices to
multiply its coefficient with ${(1 / d_{min})}^k$, which varies
between different lines.  Thus, we can compute the coefficient for a
measure once and for all (again as long as the global parameters stay
the same). 

To compute the natural width of a line, we have to compute the sum of
the coefficients of the measures on the line and the minimum of their
respective minimal time line durations.  This is a constant time
operation that does not require looping over individual measures of
the line.  

Now that we know how to compute the natural width of a line, we need
to divide the score into lines in such a way that we have the best
possible layout.  For that, we need to define the \emph{cost} of a
line.so that we can compare two different suggested lines.  In \sysname{}
we currently use the amount we have to stretch or compress it compared
to its natural width in order for it to fit on a line.  Let us define
the \emph{compress factor} of the line as the quotient between the
natural width of the line and the width of the page.  We then define
the \emph{cost} of a line as the maximum between the compress factor
and the its inverse.  That is not the only way to do it.  We might
imagine penalizing compressions more than stretches, as it might be
much harder to fit the musical material on the line when it needs to
be compressed. 

Our definition of the natural width of a measure does not take into
account extra material such as accidental that need more room.  We
could do a more precise job by adding in some extra room for such
material and count it toward the natural width of the line only if the
measure does not need to be stretched (i.e. only if the minimum
duration of the line is the same as that of the measure).  This would
only slightly complicate the method of combining measure parameters
into line parameters and it might give a considerably better result. 

However, it might not be very important to improve this calculation.
The result of the calculation is only used to divide the score into
lines and pages.  Once we display the few visible pages of the score,
we have great freedom to reorganize the material on the page.  Dense
measures might have to borrow space from less dense ones on the same
line.  As I recall, the article on the Lime music editor describes how
to do this in great detail, although it is not yet implemented in
\sysname{}.  Since usually even under very crowded conditions, space can be
reorganized within the line, the only risk we run of not having a very
precise calculation of the natural width of a line is that one line
might look slightly denser than another one on the same page, because
we did not take into account all of its accidentals. 

\section{Breaking measures into lines}

Breaking the sequence of all measures in the score into subsequences
corresponding to lines is done by an algorithm that is similar to
\emph{dynamic programming}.  Essentially, we compute all possible line
breaks and choose the best one, but thanks to dynamic programming we
avoid a possibly exponential complexity.  

But even the cubic complexity of dynamic programming would be
unacceptable for our purposes.  We transform that complexity from
cubic to constant by a series of tricks, which are documented in a
separate (unpublished) article in the same directory as this one. 

%======================================================
\chapter{\sysname{} as a {\clim} application}

%======================================================
\chapter{The {\obseq} library}

%======================================================
\chapter{Fonts}
\label{chap-fonts}

%======================================================
\chapter{Beam drawing}

It might seem like drawing beams would be trivial.  {\xwin} provides
adequate primitives to draw filled polygons that would be
generalizations of beams in a score.  As with fonts (see chapter
\ref{chap-fonts}) the problem is that anti-aliasing is called for in
order for the visual appearance to be acceptable, and that {\xwin}
does not provide for anti-aliasing in the basic protocol.  

A possibility would be to treat beams as any other character glyphs
and to write a {\metafont} program for creating beams.  The problem
with this solution is that there is a large number of different beam
slopes possible, and that a font would have to include a very large
number of them.  Furthermore, beams having fairly small slopes, turn
out to use only a small fraction of the 16 different gray-levels that
we would like to use for anti-aliasing. 

For that reason, we generate beams on an as-needed basis.  A beam is
divided into segments, each with a $\Delta y$ of $1$ (but each
possibly with a different $\Delta x$.  Each segment is drawn as a
central black rectangle surrounded by two pixmaps, each of height $1$
and the length of the segment.  One of the pixmaps provides
gray-levels from black to white and the other one from white to
black.  This method gives a smoother impression than if polygon
drawing were used.  Each new segment is similar to the previous one
(its length might vary a little) and positioned one position higher or
lower than the previous one.
